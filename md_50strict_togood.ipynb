{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 海上风电领域专业文档分类器（云端API版）\n",
    "\n",
    "## 功能\n",
    "1. 使用云端AI模型进行严格领域判定\n",
    "2. 两阶段分类流程（核心领域→专业相关领域）\n",
    "3. 并行批量处理Markdown文件\n",
    "4. 自动分类到时间戳标记的文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 配置区域 =====================\n",
    "INPUT_FOLDER = \"/home/fusion/profile/汇总需要处理的md文件/\"  # 输入目录\n",
    "CLOUD_API_URL = \"https://api.your-cloud-ai.com/v1/chat/completions\"  # 替换为实际云端API地址\n",
    "API_KEY = \"your-api-key-here\"  # 替换为实际API密钥\n",
    "MODEL_NAME = \"gpt-4-turbo\"  # 云端模型名称\n",
    "\n",
    "# 处理参数\n",
    "MAX_CHARS_FIRST = 3000  # 首次检测读取字符数\n",
    "MAX_CHARS_SECOND = 5000  # 二次检测读取字符数\n",
    "MAX_WORKERS = min(cpu_count(), 8)  # 基于CPU核心数动态调整\n",
    "TIMEOUT = 300  # 超时时间(秒)\n",
    "RETRY_LIMIT = 3  # 重试次数\n",
    "REQUEST_INTERVAL = 0.1  # 请求间隔(秒)\n",
    "BATCH_SIZE = 100  # 批次大小\n",
    "PARALLEL_PROCESSING = True  # 启用并行处理\n",
    "# ==================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import random\n",
    "import sys\n",
    "import concurrent.futures\n",
    "from multiprocessing import cpu_count\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"md_classifier_cloud.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# 生成时间戳\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 输出文件夹结构\n",
    "GOOD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"good_{timestamp}\")\n",
    "TMP_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"tmp_{timestamp}\")\n",
    "BAD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"bad_{timestamp}\")\n",
    "\n",
    "os.makedirs(GOOD_FOLDER, exist_ok=True)\n",
    "os.makedirs(TMP_FOLDER, exist_ok=True)\n",
    "os.makedirs(BAD_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词和提示模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 严格限定的海上风电领域关键词（2024年最新版）\n",
    "STRICT_KEYWORDS = {\n",
    "    # 核心技术\n",
    "    \"海上风电\", \"风机基础\", \"单桩基础\", \"导管架基础\", \"漂浮式基础\", \"张力腿平台\",\n",
    "    \"海上升压站\", \"阵列电缆\", \"送出电缆\", \"动态电缆\", \"J型管\", \"跨接管\",\n",
    "    \"防腐系统\", \"阴极保护\", \"冲刷防护\", \"风机吊装\", \"运维船\", \"人员转运系统\",\n",
    "    \"海上变电站\", \"无功补偿\", \"谐波滤波\", \"黑启动\", \"SCADA系统\", \"中央监控\",\n",
    "    \n",
    "    # 专业技术\n",
    "    \"尾流效应\", \"风资源评估\", \"LCOE\", \"平准化度电成本\", \"并网技术\", \n",
    "    \"电网适应性\", \"故障穿越\", \"海洋水文\", \"地质勘探\", \"冲刷分析\",\n",
    "    \"风机载荷\", \"疲劳分析\", \"极限强度\", \"腐蚀速率\", \"防护涂层\",\n",
    "    \n",
    "    # 英文术语\n",
    "    \"offshore wind\", \"monopile\", \"jacket foundation\", \"floating wind\",\n",
    "    \"substation\", \"inter-array cable\", \"export cable\", \"dynamic cable\",\n",
    "    \"corrosion protection\", \"cathodic protection\", \"scour protection\",\n",
    "    \"WTG\", \"FMEA\", \"HAZID\", \"SIL\", \"LCOE\", \"CAPEX\", \"OPEX\"\n",
    "}\n",
    "\n",
    "# 严格限定的相关领域关键词\n",
    "RELATED_FIELDS = {\n",
    "    # 工程领域\n",
    "    \"海洋工程\", \"海上施工\", \"海洋地质\", \"海上气象\", \"港口工程\",\n",
    "    \"船舶工程\", \"防腐工程\", \"电力工程\", \"高电压技术\",\n",
    "    \n",
    "    # 政策市场\n",
    "    \"可再生能源\", \"碳交易\", \"绿证\", \"电力市场\", \"竞价上网\",\n",
    "    \n",
    "    # 英文术语\n",
    "    \"marine engineering\", \"offshore construction\", \"renewable energy\",\n",
    "    \"carbon trading\", \"grid connection\"\n",
    "}\n",
    "\n",
    "# 首次检测提示词（核心领域严格判定）\n",
    "FIRST_PROMPT_TEMPLATE = \"\"\"\n",
    "### 海上风电核心领域严格分类\n",
    "你是一名海上风电领域专家，请严格评估以下文本是否属于海上风电核心领域。\n",
    "\n",
    "【核心特征】必须满足至少一项：\n",
    "1. 包含海上风电特有技术术语（如：单桩基础、动态电缆、LCOE等）\n",
    "2. 讨论海上风电专有技术、设备或工程问题\n",
    "3. 包含海上风电项目具体案例（需明确项目名称或技术细节）\n",
    "\n",
    "【排除条件】出现以下情况应判定为\"否\"：\n",
    "1. 仅提及一般风能或陆地风电（未明确海上场景）\n",
    "2. 仅涉及通用海洋工程（未明确风电应用）\n",
    "3. 内容过于宽泛（如仅提到\"可再生能源\"但无具体技术内容）\n",
    "\n",
    "核心关键词（参考）：\n",
    "{core_keywords}\n",
    "\n",
    "待评估文本（前{max_chars}字符）：\n",
    "{content}\n",
    "\n",
    "请严格判断后只回复\"是\"或\"否\"，不要解释：\n",
    "\"\"\"\n",
    "\n",
    "# 二次检测提示词（专业相关领域判定）\n",
    "SECOND_PROMPT_TEMPLATE = \"\"\"\n",
    "### 海上风电专业相关领域评估\n",
    "请评估以下文本是否与海上风电专业相关。\n",
    "\n",
    "【通过标准】满足任一即可：\n",
    "1. 包含海上风电相关技术讨论（即使不深入）\n",
    "2. 提及海上风电项目、政策或市场分析\n",
    "3. 涉及海上风电相关学科（如海洋工程中的风电应用）\n",
    "\n",
    "【排除标准】出现以下情况应判定为\"否\"：\n",
    "1. 完全不涉及技术、工程或专业内容\n",
    "2. 内容与能源领域完全无关（如文学、日常等）\n",
    "\n",
    "相关领域关键词（参考）：\n",
    "{related_fields}\n",
    "\n",
    "待评估文本（前{max_chars}字符）：\n",
    "{content}\n",
    "\n",
    "请判断后只回复\"是\"或\"否\"，不要解释：\n",
    "\"\"\"\n",
    "\n",
    "# 预编译正则表达式（性能优化）\n",
    "KEYWORD_PATTERN = re.compile(r'|'.join(map(re.escape, STRICT_KEYWORDS)), re.IGNORECASE)\n",
    "RELATED_PATTERN = re.compile(r'|'.join(map(re.escape, RELATED_FIELDS)), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API客户端类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIClient:\n",
    "    \"\"\"封装云端API调用\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        })\n",
    "    \n",
    "    def call_model(self, prompt: str) -> str:\n",
    "        \"\"\"调用云端模型API\"\"\"\n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"你是一名严谨的海上风电领域专家。\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 10,\n",
    "            \"response_format\": {\"type\": \"text\"}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                CLOUD_API_URL,\n",
    "                json=payload,\n",
    "                timeout=TIMEOUT\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"API请求失败: {str(e)}\")\n",
    "            raise\n",
    "        except (KeyError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"API响应解析失败: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_md_files(input_folder: str) -> List[str]:\n",
    "    \"\"\"递归查找所有Markdown文件\"\"\"\n",
    "    md_files = []\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.md'):\n",
    "                md_files.append(os.path.join(root, file))\n",
    "    return sorted(md_files)\n",
    "\n",
    "def check_filename_relevance(filename: str) -> str:\n",
    "    \"\"\"通过文件名初步分类\"\"\"\n",
    "    base_name = os.path.basename(filename).lower()\n",
    "    if KEYWORD_PATTERN.search(base_name):\n",
    "        return \"core\"\n",
    "    if RELATED_PATTERN.search(base_name):\n",
    "        return \"related\"\n",
    "    return \"unrelated\"\n",
    "\n",
    "def classify_text(content: str, prompt_template: str, max_chars: int) -> bool:\n",
    "    \"\"\"\n",
    "    使用云端模型进行文本分类\n",
    "    返回：True(相关) / False(无关)\n",
    "    \"\"\"\n",
    "    api_client = APIClient()\n",
    "    prompt = prompt_template.format(\n",
    "        core_keywords=\", \".join(sorted(STRICT_KEYWORDS)),\n",
    "        related_fields=\", \".join(sorted(RELATED_FIELDS)),\n",
    "        max_chars=max_chars,\n",
    "        content=content[:max_chars]\n",
    "    )\n",
    "    \n",
    "    for attempt in range(RETRY_LIMIT + 1):\n",
    "        try:\n",
    "            time.sleep(REQUEST_INTERVAL * (attempt + 1))\n",
    "            response = api_client.call_model(prompt).lower()\n",
    "            \n",
    "            if \"是\" in response or \"yes\" in response:\n",
    "                return True\n",
    "            elif \"否\" in response or \"no\" in response:\n",
    "                return False\n",
    "            else:\n",
    "                logger.warning(f\"模型返回异常响应: {response[:100]}...\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"分类尝试 {attempt + 1}/{RETRY_LIMIT} 失败: {str(e)}\")\n",
    "            if attempt == RETRY_LIMIT:\n",
    "                logger.error(\"达到最大重试次数，默认保留文件\")\n",
    "                return True  # 失败时默认保留\n",
    "    \n",
    "    return True  # 默认保留\n",
    "\n",
    "def cleanup_empty_directories(root_folder: str):\n",
    "    \"\"\"清理空目录\"\"\"\n",
    "    for root, dirs, _ in os.walk(root_folder, topdown=False):\n",
    "        for dir_name in dirs:\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            try:\n",
    "                if not os.listdir(dir_path):\n",
    "                    os.rmdir(dir_path)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"无法清理目录 {dir_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_first_pass(file_path: str) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"第一阶段处理：核心领域判定\"\"\"\n",
    "    try:\n",
    "        relative_path = os.path.relpath(file_path, INPUT_FOLDER)\n",
    "        good_path = os.path.join(GOOD_FOLDER, relative_path)\n",
    "        bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
    "        \n",
    "        # 跳过已处理文件\n",
    "        if os.path.exists(good_path) or os.path.exists(bad_path):\n",
    "            return (\"skip\", None)\n",
    "        \n",
    "        # 空文件检测\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return (\"empty\", None)\n",
    "        \n",
    "        # 文件名检测\n",
    "        filename_relevance = check_filename_relevance(file_path)\n",
    "        if filename_relevance == \"core\":\n",
    "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
    "            shutil.move(file_path, good_path)\n",
    "            return (\"moved\", None)\n",
    "        \n",
    "        # 需要内容检测的情况\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read(MAX_CHARS_FIRST)\n",
    "        \n",
    "        if not content.strip():\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return (\"empty\", None)\n",
    "        \n",
    "        # 核心领域分类\n",
    "        is_core = classify_text(content, FIRST_PROMPT_TEMPLATE, MAX_CHARS_FIRST)\n",
    "        \n",
    "        if is_core:\n",
    "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
    "            shutil.move(file_path, good_path)\n",
    "            return (\"moved\", None)\n",
    "        else:\n",
    "            tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
    "            shutil.move(file_path, tmp_path)\n",
    "            return (\"tmp\", tmp_path)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"首次处理失败 {file_path}: {str(e)}\")\n",
    "        relative_path = os.path.relpath(file_path, INPUT_FOLDER)\n",
    "        tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
    "        os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
    "        shutil.move(file_path, tmp_path)\n",
    "        return (\"tmp\", tmp_path)\n",
    "\n",
    "def process_second_pass(file_path: str) -> bool:\n",
    "    \"\"\"第二阶段处理：专业相关领域判定\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read(MAX_CHARS_SECOND)\n",
    "        \n",
    "        if not content.strip():\n",
    "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
    "            bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return False\n",
    "        \n",
    "        # 专业相关分类\n",
    "        is_related = classify_text(content, SECOND_PROMPT_TEMPLATE, MAX_CHARS_SECOND)\n",
    "        \n",
    "        relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
    "        if is_related:\n",
    "            good_path = os.path.join(GOOD_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
    "            shutil.move(file_path, good_path)\n",
    "            return True\n",
    "        else:\n",
    "            bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"二次处理失败 {file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def batch_process(files: List[str], process_func, desc: str) -> Dict[str, int]:\n",
    "    \"\"\"批量处理文件\"\"\"\n",
    "    stats = {\"success\": 0, \"failed\": 0, \"skipped\": 0}\n",
    "    \n",
    "    if not PARALLEL_PROCESSING:\n",
    "        for file in tqdm(files, desc=desc):\n",
    "            try:\n",
    "                result = process_func(file)\n",
    "                stats[\"success\" if result else \"failed\"] += 1\n",
    "            except Exception as e:\n",
    "                logger.error(f\"处理失败 {file}: {str(e)}\")\n",
    "                stats[\"failed\"] += 1\n",
    "        return stats\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(process_func, f): f for f in files}\n",
    "        with tqdm(total=len(files), desc=desc) as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    stats[\"success\" if result else \"failed\"] += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"处理失败: {str(e)}\")\n",
    "                    stats[\"failed\"] += 1\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主处理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"主控制流程（完整云端版）\"\"\"\n",
    "    # 初始化日志和目录\n",
    "    logger.info(\"===== 海上风电文档分类器（云端严格版）=====\")\n",
    "    logger.info(f\"输入目录: {INPUT_FOLDER}\")\n",
    "    logger.info(f\"输出目录: Good={GOOD_FOLDER} | Temp={TMP_FOLDER} | Bad={BAD_FOLDER}\")\n",
    "    logger.info(f\"使用模型: {MODEL_NAME} | 工作线程: {MAX_WORKERS} | 批次大小: {BATCH_SIZE}\")\n",
    "\n",
    "    # === 第一阶段：核心领域判定 ===\n",
    "    logger.info(\"\\n\" + \"=\"*40)\n",
    "    logger.info(\"第一阶段：核心领域严格判定\")\n",
    "    logger.info(\"=\"*40)\n",
    "    \n",
    "    first_pass_files = find_md_files(INPUT_FOLDER)\n",
    "    total_files = len(first_pass_files)\n",
    "    \n",
    "    if total_files == 0:\n",
    "        logger.info(\"输入目录中未发现Markdown文件\")\n",
    "    else:\n",
    "        logger.info(f\"开始处理 {total_files} 个文件...\")\n",
    "        \n",
    "        # 初始化统计\n",
    "        first_stats = {\n",
    "            \"core_by_name\": 0,    # 文件名直接通过\n",
    "            \"core_by_content\": 0, # 内容检测通过\n",
    "            \"to_second_pass\": 0,  # 待二次检测\n",
    "            \"empty\": 0,           # 空文件\n",
    "            \"error\": 0            # 错误文件\n",
    "        }\n",
    "\n",
    "        # 分批次处理\n",
    "        total_batches = (total_files + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "        for batch_idx in range(total_batches):\n",
    "            start = batch_idx * BATCH_SIZE\n",
    "            end = min((batch_idx + 1) * BATCH_SIZE, total_files)\n",
    "            batch_files = first_pass_files[start:end]\n",
    "            \n",
    "            logger.info(f\"\\n>> 处理批次 {batch_idx+1}/{total_batches} ({len(batch_files)}个文件)\")\n",
    "\n",
    "            if PARALLEL_PROCESSING:\n",
    "                # 并行处理\n",
    "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                    futures = {executor.submit(process_first_pass, f): f for f in batch_files}\n",
    "                    batch_results = []\n",
    "                    with tqdm(total=len(batch_files), desc=\"进度\") as pbar:\n",
    "                        for future in as_completed(futures):\n",
    "                            try:\n",
    "                                result = future.result()\n",
    "                                batch_results.append(result)\n",
    "                            except Exception as e:\n",
    "                                logger.error(f\"处理失败: {str(e)}\")\n",
    "                                batch_results.append((\"error\", None))\n",
    "                            finally:\n",
    "                                pbar.update(1)\n",
    "            else:\n",
    "                # 串行处理（调试用）\n",
    "                batch_results = []\n",
    "                for file in tqdm(batch_files, desc=\"进度\"):\n",
    "                    try:\n",
    "                        batch_results.append(process_first_pass(file))\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"处理失败 {file}: {str(e)}\")\n",
    "                        batch_results.append((\"error\", None))\n",
    "\n",
    "            # 统计本批次结果\n",
    "            for result, _ in batch_results:\n",
    "                if result == \"moved\":\n",
    "                    first_stats[\"core_by_name\"] += 1\n",
    "                elif result == \"content_passed\":\n",
    "                    first_stats[\"core_by_content\"] += 1\n",
    "                elif result == \"tmp\":\n",
    "                    first_stats[\"to_second_pass\"] += 1\n",
    "                elif result == \"empty\":\n",
    "                    first_stats[\"empty\"] += 1\n",
    "                else:\n",
    "                    first_stats[\"error\"] += 1\n",
    "\n",
    "            logger.info(\n",
    "                f\"本批次结果: \"\n",
    "                f\"文件名通过={first_stats['core_by_name']} | \"\n",
    "                f\"内容通过={first_stats['core_by_content']} | \"\n",
    "                f\"待二次检测={first_stats['to_second_pass']} | \"\n",
    "                f\"空文件={first_stats['empty']}\"\n",
    "            )\n",
    "\n",
    "        # 第一阶段总结\n",
    "        logger.info(\"\\n\" + \"=\"*40)\n",
    "        logger.info(\"第一阶段处理完成\")\n",
    "        logger.info(f\"直接通过文件: {first_stats['core_by_name'] + first_stats['core_by_content']}\")\n",
    "        logger.info(f\"待二次检测文件: {first_stats['to_second_pass']}\")\n",
    "        logger.info(f\"已过滤空文件: {first_stats['empty']}\")\n",
    "        logger.info(f\"错误文件: {first_stats['error']}\")\n",
    "\n",
    "    # === 第二阶段：专业相关领域判定 ===\n",
    "    logger.info(\"\\n\" + \"=\"*40)\n",
    "    logger.info(\"第二阶段：专业相关领域判定\")\n",
    "    logger.info(\"=\"*40)\n",
    "    \n",
    "    second_pass_files = find_md_files(TMP_FOLDER)\n",
    "    total_second_files = len(second_pass_files)\n",
    "    \n",
    "    if total_second_files == 0:\n",
    "        logger.info(\"没有需要二次检测的文件\")\n",
    "    else:\n",
    "        logger.info(f\"开始二次检测 {total_second_files} 个文件...\")\n",
    "        \n",
    "        # 初始化统计\n",
    "        second_stats = {\n",
    "            \"passed\": 0,    # 通过\n",
    "            \"rejected\": 0,  # 拒绝\n",
    "            \"error\": 0      # 错误\n",
    "        }\n",
    "\n",
    "        # 分批次处理\n",
    "        total_second_batches = (total_second_files + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "        for batch_idx in range(total_second_batches):\n",
    "            start = batch_idx * BATCH_SIZE\n",
    "            end = min((batch_idx + 1) * BATCH_SIZE, total_second_files)\n",
    "            batch_files = second_pass_files[start:end]\n",
    "            \n",
    "            logger.info(f\"\\n>> 二次检测批次 {batch_idx+1}/{total_second_batches}\")\n",
    "\n",
    "            if PARALLEL_PROCESSING:\n",
    "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                    futures = {executor.submit(process_second_pass, f): f for f in batch_files}\n",
    "                    with tqdm(total=len(batch_files), desc=\"进度\") as pbar:\n",
    "                        for future in as_completed(futures):\n",
    "                            try:\n",
    "                                if future.result():\n",
    "                                    second_stats[\"passed\"] += 1\n",
    "                                else:\n",
    "                                    second_stats[\"rejected\"] += 1\n",
    "                            except Exception as e:\n",
    "                                logger.error(f\"处理失败: {str(e)}\")\n",
    "                                second_stats[\"error\"] += 1\n",
    "                            finally:\n",
    "                                pbar.update(1)\n",
    "            else:\n",
    "                for file in tqdm(batch_files, desc=\"进度\"):\n",
    "                    try:\n",
    "                        if process_second_pass(file):\n",
    "                            second_stats[\"passed\"] += 1\n",
    "                        else:\n",
    "                            second_stats[\"rejected\"] += 1\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"处理失败 {file}: {str(e)}\")\n",
    "                        second_stats[\"error\"] += 1\n",
    "\n",
    "            logger.info(\n",
    "                f\"本批次结果: \"\n",
    "                f\"通过={second_stats['passed']} | \"\n",
    "                f\"拒绝={second_stats['rejected']} | \"\n",
    "                f\"错误={second_stats['error']}\"\n",
    "            )\n",
    "\n",
    "        # 第二阶段总结\n",
    "        logger.info(\"\\n\" + \"=\"*40)\n",
    "        logger.info(\"第二阶段处理完成\")\n",
    "        logger.info(f\"最终通过文件: {second_stats['passed']}\")\n",
    "        logger.info(f\"最终拒绝文件: {second_stats['rejected']}\")\n",
    "        logger.info(f\"错误文件: {second_stats['error']}\")\n",
    "\n",
    "    # === 最终清理和统计 ===\n",
    "    logger.info(\"\\n\" + \"=\"*40)\n",
    "    logger.info(\"执行清理操作\")\n",
    "    logger.info(\"=\"*40)\n",
    "    \n",
    "    cleanup_empty_directories(INPUT_FOLDER)\n",
    "    cleanup_empty_directories(TMP_FOLDER)\n",
    "    \n",
    "    # 最终报告\n",
    "    logger.info(\"\\n\" + \"=\"*60)\n",
    "    logger.info(\"处理完成！最终统计\")\n",
    "    logger.info(f\"总处理文件数: {total_files}\")\n",
    "    logger.info(f\"最终通过文件: {first_stats.get('core_by_name',0) + first_stats.get('core_by_content',0) + second_stats.get('passed',0)}\")\n",
    "    logger.info(f\"最终拒绝文件: {first_stats.get('empty',0) + second_stats.get('rejected',0)}\")\n",
    "    logger.info(f\"临时保留文件: {first_stats.get('to_second_pass',0) + second_stats.get('error',0)}\")\n",
    "    logger.info(f\"通过文件存放位置: {GOOD_FOLDER}\")\n",
    "    logger.info(f\"拒绝文件存放位置: {BAD_FOLDER}\")\n",
    "    logger.info(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        logger.warning(\"程序被用户中断\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"程序异常终止: {str(e)}\", exc_info=True)\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
