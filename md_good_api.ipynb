{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 海上风电文档分类器（阿里云百炼版）\n",
    "\n",
    "该Notebook实现了基于阿里云百炼深度学习模型的Markdown文件自动分类，支持两阶段分类流程。\n",
    "\n",
    "核心功能包括：\n",
    "- 递归扫描输入目录中的所有.md文件\n",
    "- 基于文件名关键词进行初步筛选\n",
    "- 使用阿里云模型对文件内容进行两次文本分类\n",
    "- 根据分类结果移动文件到对应文件夹（good/tmp/bad）\n",
    "- 支持日志记录、异常处理、并发处理\n",
    "\n",
    "适合需要快速筛选大量技术文档的场景。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 导入依赖库\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count\n",
    "from openai import OpenAI  # 阿里云百炼SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置参数区\n",
    "- 输入输出路径\n",
    "- 模型信息和API密钥\n",
    "- 并发参数、超时、重试次数等\n",
    "- 关键词集合\n",
    "- 提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============== 配置区域 ===============\n",
    "INPUT_FOLDER = \"/home/fusion/profile/before0621/md_output_20250731_115811/batch_1/\"\n",
    "DASHSCOPE_API_KEY = \"sk-73748cae71ed4f758c93b0ccd03c0cda\"\n",
    "DASHSCOPE_BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"\n",
    "MAX_CHARS_FIRST = 3000\n",
    "MAX_CHARS_SECOND = 5000\n",
    "GPU_ENABLED = True\n",
    "NUM_GPU = 2\n",
    "MAX_WORKERS = min(cpu_count(), 2)\n",
    "TIMEOUT = 300\n",
    "RETRY_LIMIT = 3\n",
    "REQUEST_INTERVAL = 1\n",
    "BATCH_SIZE = 10\n",
    "PARALLEL_PROCESSING = False\n",
    "# ========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志配置\n",
    "- 同时输出到文件和控制台\n",
    "- 方便排查问题和进度监控"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"md_classifier_gpu.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出目录定义\n",
    "- 自动根据当前时间戳创建输出文件夹\n",
    "- 分类结果文件分别存放到good/tmp/bad文件夹"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "GOOD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"good_{timestamp}\")\n",
    "TMP_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"tmp_{timestamp}\")\n",
    "BAD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"bad_{timestamp}\")\n",
    "\n",
    "os.makedirs(GOOD_FOLDER, exist_ok=True)\n",
    "os.makedirs(TMP_FOLDER, exist_ok=True)\n",
    "os.makedirs(BAD_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词定义\n",
    "- 核心关键词集合\n",
    "- 相关领域关键词集合\n",
    "- 用集合提高查找效率"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CORE_KEYWORDS = {\n",
    "    \"海上风电\", \"风机\", \"风力发电机\", \"海缆\", \"海底电缆\",\n",
    "    \"单桩\", \"单桩基础\", \"升压站\", \"防腐涂层\", \"LCOE\",\n",
    "    \"平准化度电成本\", \"尾流效应\", \"地质勘探\", \"风电场设计\",\n",
    "    \"海上施工\", \"风机安装\", \"运维\", \"海上风电场规划\",\n",
    "    \"offshore wind\", \"wind turbine\", \"wind generator\",\n",
    "    \"submarine cable\", \"undersea cable\", \"monopile\",\n",
    "    \"monopile foundation\", \"substation\", \"anticorrosive coating\",\n",
    "    \"levelized cost of electricity\", \"wake effect\", \"geological survey\",\n",
    "    \"wind farm design\", \"offshore construction\", \"turbine installation\",\n",
    "    \"operation and maintenance\", \"offshore wind planning\"\n",
    "}\n",
    "\n",
    "RELATED_FIELDS = {\n",
    "    \"海洋工程\", \"海洋技术\", \"动力学\", \"结构工程\", \"岩土工程\",\n",
    "    \"并网技术\", \"风场\", \"风电场\", \"腐蚀防护\", \"海上气象\",\n",
    "    \"海上可再生能源\", \"可再生能源\", \"海洋能源\",\n",
    "    \"清洁能源技术\", \"船舶工程\", \"港口建设\", \"海洋环境\",\n",
    "    \"marine engineering\", \"ocean technology\", \"dynamics\",\n",
    "    \"structural engineering\", \"geotechnical engineering\",\n",
    "    \"grid connection technology\", \"wind farm\", \"corrosion protection\",\n",
    "    \"marine meteorology\", \"offshore renewable energy\",\n",
    "    \"renewable energy\", \"marine energy\", \"clean energy technology\",\n",
    "    \"naval architecture\", \"port construction\", \"marine environment\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提示词模板\n",
    "- 分别用于首次检测和二次检测\n",
    "- 包含关键词列表和判断标准\n",
    "- 限制读取文本长度"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "FIRST_PROMPT_TEMPLATE = \"\"\"\n",
    "### 海上风电领域首次分类\n",
    "**核心关键词**: {core_keywords}\n",
    "**邻近领域**: {related_fields}\n",
    "\n",
    "**判断标准**:\n",
    "1. 包含任一核心关键词或邻近领域关键词 → 是\n",
    "2. 内容涉及海洋、风能、工程等海上风电相关领域 → 是\n",
    "3. 文件可能包含与海上风电间接相关的信息 → 是\n",
    "4. 完全不涉及任何技术或相关领域内容 → 否\n",
    "\n",
    "**待评估文本(前{max_chars}字符)**:\n",
    "{content}\n",
    "\n",
    "**输出**: 仅\"是\"或\"否\"\n",
    "\"\"\"\n",
    "\n",
    "SECOND_PROMPT_TEMPLATE = \"\"\"\n",
    "### 海上风电领域二次分类\n",
    "**核心关键词**: {core_keywords}\n",
    "**邻近领域**: {related_fields}\n",
    "\n",
    "**判断标准**:\n",
    "1. 文本中包含任何海上风电相关关键词 → 是\n",
    "2. 内容涉及海洋、能源或工程领域的通用知识 → 是\n",
    "3. 文件可能包含对海上风电有价值的信息 → 是\n",
    "4. 完全不相关的领域（如纯文学、娱乐、个人日常等） → 否\n",
    "\n",
    "**待评估文本(前{max_chars}字符)**:\n",
    "{content}\n",
    "\n",
    "**输出**: 仅\"是\"或\"否\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预编译正则表达式\n",
    "- 合并核心和相关领域关键词，方便全文匹配\n",
    "- 使用忽略大小写模式"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ALL_KEYWORDS = CORE_KEYWORDS.union(RELATED_FIELDS)\n",
    "KEYWORD_PATTERN = re.compile(r'|'.join(re.escape(kw) for kw in ALL_KEYWORDS), re.IGNORECASE)\n",
    "CORE_KEYWORD_PATTERN = re.compile(r'|'.join(re.escape(kw) for kw in CORE_KEYWORDS), re.IGNORECASE)\n",
    "RELATED_KEYWORD_PATTERN = re.compile(r'|'.join(re.escape(kw) for kw in RELATED_FIELDS), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建阿里云百炼OpenAI客户端实例"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dashscope_client = OpenAI(\n",
    "    api_key=DASHSCOPE_API_KEY,\n",
    "    base_url=DASHSCOPE_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键功能函数定义\n",
    "\n",
    "- 测试阿里云服务连接\n",
    "- 递归查找.md文件\n",
    "- 关键词匹配\n",
    "- 文件名关联判断\n",
    "- 文本分类调用\n",
    "- 文件移动及异常处理\n",
    "- 清理空目录"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def test_dashscope_connection():\n",
    "    \"\"\"测试阿里云百炼连接和模型可用性\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"测试阿里云百炼服务连接: {DASHSCOPE_BASE_URL}\")\n",
    "\n",
    "        response = dashscope_client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"测试连接\"}],\n",
    "            max_tokens=5,\n",
    "            timeout=10\n",
    "        )\n",
    "\n",
    "        if response.choices[0].message.content:\n",
    "            logger.info(f\"阿里云百炼服务连接成功，模型响应正常\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.error(f\"模型验证失败: 无有效响应内容\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"阿里云百炼连接失败: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def find_md_files(input_folder):\n",
    "    \"\"\"递归遍历文件夹，查找所有 .md 文件\"\"\"\n",
    "    md_files = []\n",
    "    for root, dirs, files in os.walk(input_folder, topdown=True):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.md'):\n",
    "                md_files.append(os.path.join(root, file))\n",
    "    return md_files\n",
    "\n",
    "\n",
    "def check_dashscope_health():\n",
    "    \"\"\"检查阿里云百炼服务状态\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"检查阿里云百炼服务状态: {DASHSCOPE_BASE_URL}\")\n",
    "\n",
    "        response = dashscope_client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"健康检查\"}],\n",
    "            max_tokens=5,\n",
    "            timeout=15\n",
    "        )\n",
    "\n",
    "        if response.choices[0].message.content:\n",
    "            logger.info(\"阿里云百炼服务健康检查通过\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.warning(\"服务响应异常，但模型可能可用\")\n",
    "            return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"阿里云百炼健康检查失败: {str(e)}\")\n",
    "        logger.warning(\"忽略错误，继续执行...\")\n",
    "        return True\n",
    "\n",
    "\n",
    "def contains_keywords(text):\n",
    "    \"\"\"关键词快速匹配（中英文不区分大小写）\"\"\"\n",
    "    try:\n",
    "        return bool(KEYWORD_PATTERN.search(text))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"关键词匹配失败: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_filename_relevance(filename):\n",
    "    \"\"\"文件名多语言检测（优化正则匹配）\"\"\"\n",
    "    base_name = os.path.basename(filename).lower()\n",
    "    if CORE_KEYWORD_PATTERN.search(base_name):\n",
    "        return \"core\"\n",
    "    if RELATED_KEYWORD_PATTERN.search(base_name):\n",
    "        return \"related\"\n",
    "    return \"unrelated\"\n",
    "\n",
    "\n",
    "def classify_text(content, prompt_template, max_chars, retry_count=0):\n",
    "    \"\"\"通用分类函数（优化请求参数）\"\"\"\n",
    "    if retry_count > RETRY_LIMIT:\n",
    "        logger.warning(f\"达最大重试次数，放弃\")\n",
    "        return True  # 默认通过，避免阻塞\n",
    "\n",
    "    try:\n",
    "        prompt = prompt_template.format(\n",
    "            core_keywords=\", \".join(CORE_KEYWORDS),\n",
    "            related_fields=\", \".join(RELATED_FIELDS),\n",
    "            max_chars=max_chars,\n",
    "            content=content[:max_chars]\n",
    "        )\n",
    "\n",
    "        time.sleep(random.uniform(0, REQUEST_INTERVAL))\n",
    "\n",
    "        response = dashscope_client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            top_p=0.9,\n",
    "            max_tokens=50,\n",
    "            timeout=TIMEOUT\n",
    "        )\n",
    "\n",
    "        res_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        if \"是\" in res_text or \"相关\" in res_text or \"yes\" in res_text.lower() or \"保留\" in res_text:\n",
    "            return True\n",
    "        elif \"否\" in res_text or \"无关\" in res_text or \"no\" in res_text.lower() or \"删除\" in res_text:\n",
    "            return False\n",
    "        else:\n",
    "            logger.warning(f\"异常响应: {res_text[:50]}，默认保留\")\n",
    "            return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"分类失败: {str(e)}\")\n",
    "        return classify_text(content, prompt_template, max_chars, retry_count + 1)\n",
    "\n",
    "\n",
    "def process_first_pass(file_path):\n",
    "    \"\"\"首次处理：核心和邻近领域标准\"\"\"\n",
    "    try:\n",
    "        relative_path = os.path.relpath(file_path, INPUT_FOLDER)\n",
    "        good_path = os.path.join(GOOD_FOLDER, relative_path)\n",
    "        bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
    "\n",
    "        if os.path.exists(good_path) or os.path.exists(bad_path):\n",
    "            return (\"skip\", None)\n",
    "\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return (\"empty\", None)\n",
    "\n",
    "        filename_relevance = check_filename_relevance(file_path)\n",
    "        if filename_relevance == \"core\":\n",
    "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
    "            shutil.move(file_path, good_path)\n",
    "            return (\"moved\", None)\n",
    "        elif filename_relevance == \"related\":\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read(MAX_CHARS_FIRST)\n",
    "\n",
    "            if not content.strip():\n",
    "                os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "                shutil.move(file_path, bad_path)\n",
    "                return (\"empty\", None)\n",
    "\n",
    "            is_related = classify_text(content, FIRST_PROMPT_TEMPLATE, MAX_CHARS_FIRST)\n",
    "\n",
    "            if is_related:\n",
    "                os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
    "                shutil.move(file_path, good_path)\n",
    "                return (\"moved\", None)\n",
    "            else:\n",
    "                tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
    "                os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
    "                shutil.move(file_path, tmp_path)\n",
    "                return (\"tmp\", tmp_path)\n",
    "        else:\n",
    "            tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
    "            shutil.move(file_path, tmp_path)\n",
    "            return (\"tmp\", tmp_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"首次处理失败 {file_path}: {str(e)}\")\n",
    "        relative_path = os.path.relpath(file_path, INPUT_FOLDER)\n",
    "        tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
    "        os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
    "        shutil.move(file_path, tmp_path)\n",
    "        return (\"tmp\", tmp_path)\n",
    "\n",
    "\n",
    "def process_second_pass(file_path):\n",
    "    \"\"\"二次处理：核心和邻近领域标准\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read(MAX_CHARS_SECOND)\n",
    "\n",
    "        if not content.strip():\n",
    "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
    "            bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return False\n",
    "\n",
    "        is_related = classify_text(content, SECOND_PROMPT_TEMPLATE, MAX_CHARS_SECOND)\n",
    "\n",
    "        if is_related:\n",
    "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
    "            good_path = os.path.join(GOOD_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
    "            shutil.move(file_path, good_path)\n",
    "            return True\n",
    "        else:\n",
    "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
    "            bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
    "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
    "            shutil.move(file_path, bad_path)\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"二次处理失败 {file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def cleanup_empty_directories(root_folder):\n",
    "    \"\"\"清理空目录（支持并行和串行）\"\"\"\n",
    "    if not PARALLEL_PROCESSING:\n",
    "        for root, dirs, _ in os.walk(root_folder, topdown=False):\n",
    "            for dir_name in dirs:\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                try:\n",
    "                    if not os.listdir(dir_path):\n",
    "                        os.rmdir(dir_path)\n",
    "                        logger.debug(f\"清理空目录: {dir_path}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"无法清理目录 {dir_path}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # 并行清理\n",
    "    dirs_to_check = []\n",
    "    for root, dirs, _ in os.walk(root_folder, topdown=False):\n",
    "        for dir_name in dirs:\n",
    "            dirs_to_check.append(os.path.join(root, dir_name))\n",
    "\n",
    "    def remove_if_empty(dir_path):\n",
    "        try:\n",
    "            if not os.listdir(dir_path):\n",
    "                os.rmdir(dir_path)\n",
    "                logger.debug(f\"清理空目录: {dir_path}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"无法清理目录 {dir_path}: {str(e)}\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        list(tqdm(executor.map(remove_if_empty, dirs_to_check),\n",
    "                  total=len(dirs_to_check), desc=\"清理空目录\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数\n",
    "- 按批次处理原始输入目录中的文件\n",
    "- 记录统计信息\n",
    "- 清理空目录\n",
    "- 处理tmp文件夹进行二次检测\n",
    "- 记录最终结果"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def main():\n",
    "    logger.info(\"===== 海上风电文档分类器（阿里云百炼版）启动 =====\")\n",
    "    logger.info(f\"输入目录: {INPUT_FOLDER}\")\n",
    "    logger.info(f\"使用模型: {MODEL_NAME} | 批次大小: {BATCH_SIZE}\")\n",
    "    logger.info(f\"API地址: {DASHSCOPE_BASE_URL}\")\n",
    "\n",
    "    if not test_dashscope_connection() or not check_dashscope_health():\n",
    "        logger.error(\"服务检查失败，但继续执行...\")\n",
    "\n",
    "    # 第一阶段处理原始文件夹\n",
    "    logger.info(\"===== 开始第一阶段：处理原始文件夹中的文件 =====\")\n",
    "    first_pass_files = find_md_files(INPUT_FOLDER)\n",
    "    total_files = len(first_pass_files)\n",
    "    if total_files == 0:\n",
    "        logger.info(\"原始文件夹中未找到MD文件，直接进入第二阶段\")\n",
    "    else:\n",
    "        logger.info(f\"共找到 {total_files} 个MD文件，开始分批次处理...\")\n",
    "\n",
    "        first_stats = {\"moved\": 0, \"tmp\": 0, \"empty\": 0, \"error\": 0, \"skip\": 0}\n",
    "        total_batch = (total_files + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "        for batch_idx in range(total_batch):\n",
    "            start = batch_idx * BATCH_SIZE\n",
    "            end = min((batch_idx + 1) * BATCH_SIZE, total_files)\n",
    "            batch_files = first_pass_files[start:end]\n",
    "            batch_num = batch_idx + 1\n",
    "            logger.info(f\"\\n===== 批次 {batch_num}/{total_batch} 开始（{len(batch_files)}个文件） =====\")\n",
    "\n",
    "            batch_stats = {\"moved\": 0, \"tmp\": 0, \"empty\": 0, \"error\": 0, \"skip\": 0}\n",
    "\n",
    "            if not PARALLEL_PROCESSING:\n",
    "                for file in tqdm(batch_files, desc=f\"批次{batch_num}处理\"):\n",
    "                    try:\n",
    "                        result, _ = process_first_pass(file)\n",
    "                        batch_stats[result] += 1\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"处理异常: {str(e)}\")\n",
    "                        batch_stats[\"error\"] += 1\n",
    "            else:\n",
    "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                    futures = {executor.submit(process_first_pass, f): f for f in batch_files}\n",
    "                    with tqdm(total=len(batch_files), desc=f\"批次{batch_num}处理\") as pbar:\n",
    "                        for future in as_completed(futures):\n",
    "                            try:\n",
    "                                result, _ = future.result()\n",
    "                                batch_stats[result] += 1\n",
    "                                pbar.update(1)\n",
    "                            except Exception as e:\n",
    "                                logger.error(f\"批次{batch_num}任务异常: {str(e)}\")\n",
    "                                batch_stats[\"error\"] += 1\n",
    "                                pbar.update(1)\n",
    "\n",
    "            first_stats[\"moved\"] += batch_stats[\"moved\"]\n",
    "            first_stats[\"tmp\"] += batch_stats[\"tmp\"]\n",
    "            first_stats[\"empty\"] += batch_stats[\"empty\"]\n",
    "            first_stats[\"error\"] += batch_stats[\"error\"]\n",
    "            first_stats[\"skip\"] += batch_stats[\"skip\"]\n",
    "\n",
    "            logger.info(f\"批次{batch_num}处理结果: \"\n",
    "                        f\"通过={batch_stats['moved']}, \"\n",
    "                        f\"待二次检测={batch_stats['tmp']}, \"\n",
    "                        f\"空文件={batch_stats['empty']}, \"\n",
    "                        f\"错误={batch_stats['error']}\")\n",
    "\n",
    "        logger.info(\"\\n\" + \"=\" * 60)\n",
    "        logger.info(\"第一阶段处理完成！\")\n",
    "        logger.info(f\"第一阶段统计:\")\n",
    "        logger.info(f\"  直接通过文件: {first_stats['moved']}（已移动到good文件夹）\")\n",
    "        logger.info(f\"  待二次检测文件: {first_stats['tmp']}（已移动到tmp文件夹）\")\n",
    "        logger.info(f\"  空文件: {first_stats['empty']}（已移动到bad文件夹）\")\n",
    "        logger.info(f\"  错误文件: {first_stats['error']}（已移动到bad文件夹）\")\n",
    "        logger.info(f\"  跳过文件: {first_stats['skip']}\")\n",
    "        logger.info(\"=\" * 60)\n",
    "\n",
    "        cleanup_empty_directories(INPUT_FOLDER)\n",
    "        logger.info(f\"原始文件夹空目录清理完成，当前状态: {'空' if not os.listdir(INPUT_FOLDER) else '非空'}\")\n",
    "\n",
    "    # 第二阶段处理tmp文件夹\n",
    "    logger.info(\"\\n===== 开始第二阶段：处理tmp文件夹中的文件 =====\")\n",
    "    second_pass_files = find_md_files(TMP_FOLDER)\n",
    "    total_second_files = len(second_pass_files)\n",
    "    if total_second_files == 0:\n",
    "        logger.info(\"tmp文件夹中未找到MD文件，处理完成\")\n",
    "    else:\n",
    "        logger.info(f\"tmp文件夹中共找到 {total_second_files} 个MD文件，开始二次检测...\")\n",
    "\n",
    "        second_stats = {\"moved\": 0, \"rejected\": 0, \"error\": 0}\n",
    "        total_second_batch = (total_second_files + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "        for batch_idx in range(total_second_batch):\n",
    "            start = batch_idx * BATCH_SIZE\n",
    "            end = min((batch_idx + 1) * BATCH_SIZE, total_second_files)\n",
    "            batch_files = second_pass_files[start:end]\n",
    "            batch_num = batch_idx + 1\n",
    "            logger.info(f\"\\n===== 二次检测批次 {batch_num}/{total_second_batch} 开始 =====\")\n",
    "\n",
    "            batch_stats = {\"moved\": 0, \"rejected\": 0, \"error\": 0}\n",
    "\n",
    "            if not PARALLEL_PROCESSING:\n",
    "                for file in tqdm(batch_files, desc=f\"批次{batch_num}二次检测\"):\n",
    "                    try:\n",
    "                        if process_second_pass(file):\n",
    "                            batch_stats[\"moved\"] += 1\n",
    "                        else:\n",
    "                            batch_stats[\"rejected\"] += 1\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"处理异常: {str(e)}\")\n",
    "                        batch_stats[\"error\"] += 1\n",
    "            else:\n",
    "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                    futures = {executor.submit(process_second_pass, f): f for f in batch_files}\n",
    "                    with tqdm(total=len(batch_files), desc=f\"批次{batch_num}二次检测\") as pbar:\n",
    "                        for future in as_completed(futures):\n",
    "                            try:\n",
    "                                if future.result():\n",
    "                                    batch_stats[\"moved\"] += 1\n",
    "                                else:\n",
    "                                    batch_stats[\"rejected\"] += 1\n",
    "                                pbar.update(1)\n",
    "                            except Exception as e:\n",
    "                                logger.error(f\"批次{batch_num}任务异常: {str(e)}\")\n",
    "                                batch_stats[\"error\"] += 1\n",
    "                                pbar.update(1)\n",
    "\n",
    "            second_stats[\"moved\"] += batch_stats[\"moved\"]\n",
    "            second_stats[\"rejected\"] += batch_stats[\"rejected\"]\n",
    "            second_stats[\"error\"] += batch_stats[\"error\"]\n",
    "\n",
    "            logger.info(f\"二次检测批次{batch_num}结果: \"\n",
    "                        f\"通过={batch_stats['moved']}（已移动到good文件夹）, \"\n",
    "                        f\"拒绝={batch_stats['rejected']}（已移动到bad文件夹）, \"\n",
    "                        f\"错误={batch_stats['error']}\")\n",
    "\n",
    "        logger.info(\"\\n\" + \"=\" * 60)\n",
    "        logger.info(\"第二阶段处理完成！\")\n",
    "        logger.info(f\"第二阶段统计:\")\n",
    "        logger.info(f\"  二次检测通过文件: {second_stats['moved']}（已移动到good文件夹）\")\n",
    "        logger.info(f\"  最终拒绝文件: {second_stats['rejected']}（已移动到bad文件夹）\")\n",
    "        logger.info(f\"  错误文件: {second_stats['error']}（保留在tmp文件夹）\")\n",
    "        logger.info(\"=\" * 60)\n",
    "\n",
    "        cleanup_empty_directories(TMP_FOLDER)\n",
    "        logger.info(f\"tmp文件夹空目录清理完成，当前状态: {'空' if not os.listdir(TMP_FOLDER) else '非空'}\")\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\" * 60)\n",
    "    logger.info(\"所有文件处理完成！\")\n",
    "    logger.info(f\"最终统计:\")\n",
    "    logger.info(f\"  通过文件总数: {first_stats.get('moved', 0) + second_stats.get('moved', 0)}\")\n",
    "    logger.info(f\"  拒绝文件: {first_stats.get('empty', 0) + second_stats.get('rejected', 0)}\")\n",
    "    logger.info(f\"  临时保留文件: {first_stats.get('tmp', 0) + second_stats.get('error', 0)}\")\n",
    "    logger.info(f\"  原始文件夹状态: {'空' if not os.listdir(INPUT_FOLDER) else '非空'}\")\n",
    "    logger.info(f\"  通过文件存放于: {GOOD_FOLDER}\")\n",
    "    logger.info(f\"  拒绝文件存放于: {BAD_FOLDER}\")\n",
    "    logger.info(f\"  临时保留文件存放于: {TMP_FOLDER}\")\n",
    "    logger.info(\"=\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        logger.warning(\"程序被用户中断\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"程序异常终止: {str(e)}\")\n",
    "        sys.exit(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}```json
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 海上风电文档分类器（阿里云百炼版）\n",
        "\n",
        "该脚本用于批量分类Markdown文件，判断文件内容是否与海上风电领域相关，分为核心关键词、邻近领域关键词两阶段分类。使用阿里云百炼API做文本分类判断，支持多线程处理，支持GPU模型调用，自动将文件移动到 `good`、`tmp`、`bad` 目录。\n",
        "\n",
        "## 主要功能\n",
        "- 递归扫描指定输入文件夹，查找所有 `.md` 文件\n",
        "- 根据文件名关键词快速预判相关性，核心关键词文件直接通过\n",
        "- 核心关键词和邻近领域关键词文本分类二次判断\n",
        "- 支持超时、重试，保证稳定运行\n",
        "- 线程安全日志输出和进度条显示\n",
        "- 自动清理空目录\n",
        "- 详细的日志记录\n",
        "\n",
        "## 配置参数\n",
        "- `INPUT_FOLDER`: 待处理的Markdown文件根目录\n",
        "- `DASHSCOPE_API_KEY`: 阿里云百炼API密钥\n",
        "- `DASHSCOPE_BASE_URL`: API基础地址\n",
        "- `MODEL_NAME`: 使用的阿里云模型名称\n",
        "- `MAX_CHARS_FIRST` 和 `MAX_CHARS_SECOND`: 初次与二次检测读取字符数\n",
        "- `BATCH_SIZE`: 分批处理大小\n",
        "- `PARALLEL_PROCESSING`: 是否启用并行处理\n",
        "\n",
        "## 运行说明\n",
        "执行脚本后，程序自动进行两阶段文件分类，输出日志并将文件移动到对应目录。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# 导入必要库\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import logging\n",
        "import re\n",
        "import random\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from multiprocessing import cpu_count\n",
        "import threading\n",
        "from openai import OpenAI  # 引入阿里云百炼OpenAI客户端\n",
        "\n",
        "# ===================== 配置区域 =====================\n",
        "INPUT_FOLDER = \"/home/fusion/profile/before0621/md_output_20250731_115811/batch_1/\"  # 输入目录\n",
        "DASHSCOPE_API_KEY = \"sk-73748cae71ed4f758c93b0ccd03c0cda\"  # 阿里云API密钥\n",
        "DASHSCOPE_BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # 阿里云API地址\n",
        "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"  # 阿里云模型名称\n",
        "MAX_CHARS_FIRST = 3000  # 首次检测读取字符数\n",
        "MAX_CHARS_SECOND = 5000  # 二次检测读取字符数\n",
        "GPU_ENABLED = True  # 是否启用GPU加速（模型已配置）\n",
        "NUM_GPU = 2  # 使用GPU数量\n",
        "MAX_WORKERS = min(cpu_count(), 2)  # 最大线程数，基于CPU核心动态调整\n",
        "TIMEOUT = 300  # 请求超时秒数\n",
        "RETRY_LIMIT = 3  # 请求重试次数\n",
        "REQUEST_INTERVAL = 1  # 请求间隔秒数（避免频繁请求）\n",
        "BATCH_SIZE = 10  # 批处理文件数\n",
        "PARALLEL_PROCESSING = False  # 是否启用并行处理\n",
        "# ===================================================\n",
        "\n",
        "# 日志配置\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"md_classifier_gpu.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger()\n",
        "\n",
        "# 生成时间戳，用于动态创建输出目录\n",
        "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# 定义输出目录\n",
        "GOOD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"good_{timestamp}\")\n",
        "TMP_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"tmp_{timestamp}\")\n",
        "BAD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(INPUT_FOLDER)), f\"bad_{timestamp}\")\n",
        "\n",
        "# 创建目录\n",
        "os.makedirs(GOOD_FOLDER, exist_ok=True)\n",
        "os.makedirs(TMP_FOLDER, exist_ok=True)\n",
        "os.makedirs(BAD_FOLDER, exist_ok=True)\n",
        "\n",
        "# 核心关键词集合（中英文混合）\n",
        "CORE_KEYWORDS = {\n",
        "    \"海上风电\", \"风机\", \"风力发电机\", \"海缆\", \"海底电缆\",\n",
        "    \"单桩\", \"单桩基础\", \"升压站\", \"防腐涂层\", \"LCOE\",\n",
        "    \"平准化度电成本\", \"尾流效应\", \"地质勘探\", \"风电场设计\",\n",
        "    \"海上施工\", \"风机安装\", \"运维\", \"海上风电场规划\",\n",
        "    \"offshore wind\", \"wind turbine\", \"wind generator\",\n",
        "    \"submarine cable\", \"undersea cable\", \"monopile\",\n",
        "    \"monopile foundation\", \"substation\", \"anticorrosive coating\",\n",
        "    \"levelized cost of electricity\", \"wake effect\", \"geological survey\",\n",
        "    \"wind farm design\", \"offshore construction\", \"turbine installation\",\n",
        "    \"operation and maintenance\", \"offshore wind planning\"\n",
        "}\n",
        "\n",
        "# 相关领域关键词集合\n",
        "RELATED_FIELDS = {\n",
        "    \"海洋工程\", \"海洋技术\", \"动力学\", \"结构工程\", \"岩土工程\",\n",
        "    \"并网技术\", \"风场\", \"风电场\", \"腐蚀防护\", \"海上气象\",\n",
        "    \"海上可再生能源\", \"可再生能源\", \"海洋能源\",\n",
        "    \"清洁能源技术\", \"船舶工程\", \"港口建设\", \"海洋环境\",\n",
        "    \"marine engineering\", \"ocean technology\", \"dynamics\",\n",
        "    \"structural engineering\", \"geotechnical engineering\",\n",
        "    \"grid connection technology\", \"wind farm\", \"corrosion protection\",\n",
        "    \"marine meteorology\", \"offshore renewable energy\",\n",
        "    \"renewable energy\", \"marine energy\", \"clean energy technology\",\n",
        "    \"naval architecture\", \"port construction\", \"marine environment\"\n",
        "}\n",
        "\n",
        "# 首次检测提示词模板\n",
        "FIRST_PROMPT_TEMPLATE = \"\"\"\n",
        "### 海上风电领域首次分类\n",
        "**核心关键词**: {core_keywords}\n",
        "**邻近领域**: {related_fields}\n",
        "\n",
        "**判断标准**:\n",
        "1. 包含任一核心关键词或邻近领域关键词 → 是\n",
        "2. 内容涉及海洋、风能、工程等海上风电相关领域 → 是\n",
        "3. 文件可能包含与海上风电间接相关的信息 → 是\n",
        "4. 完全不涉及任何技术或相关领域内容 → 否\n",
        "\n",
        "**待评估文本(前{max_chars}字符)**:\n",
        "{content}\n",
        "\n",
        "**输出**: 仅\"是\"或\"否\"\n",
        "\"\"\"\n",
        "\n",
        "# 二次检测提示词模板\n",
        "SECOND_PROMPT_TEMPLATE = \"\"\"\n",
        "### 海上风电领域二次分类\n",
        "**核心关键词**: {core_keywords}\n",
        "**邻近领域**: {related_fields}\n",
        "\n",
        "**判断标准**:\n",
        "1. 文本中包含任何海上风电相关关键词 → 是\n",
        "2. 内容涉及海洋、能源或工程领域的通用知识 → 是\n",
        "3. 文件可能包含对海上风电有价值的信息 → 是\n",
        "4. 完全不相关的领域（如纯文学、娱乐、个人日常等） → 否\n",
        "\n",
        "**待评估文本(前{max_chars}字符)**:\n",
        "{content}\n",
        "\n",
        "**输出**: 仅\"是\"或\"否\"\n",
        "\"\"\"\n",
        "\n",
        "# 线程锁，保证日志打印和文件操作线程安全\n",
        "print_lock = threading.Lock()\n",
        "output_lock = threading.Lock()\n",
        "\n",
        "# 预编译关键词匹配正则（忽略大小写）\n",
        "ALL_KEYWORDS = CORE_KEYWORDS.union(RELATED_FIELDS)\n",
        "KEYWORD_PATTERN = re.compile(r'|'.join(re.escape(kw) for kw in ALL_KEYWORDS), re.IGNORECASE)\n",
        "CORE_KEYWORD_PATTERN = re.compile(r'|'.join(re.escape(kw) for kw in CORE_KEYWORDS), re.IGNORECASE)\n",
        "RELATED_KEYWORD_PATTERN = re.compile(r'|'.join(re.escape(kw) for kw in RELATED_FIELDS), re.IGNORECASE)\n",
        "\n",
        "# 初始化阿里云百炼OpenAI客户端\n",
        "dashscope_client = OpenAI(\n",
        "    api_key=DASHSCOPE_API_KEY,\n",
        "    base_url=DASHSCOPE_BASE_URL\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def test_dashscope_connection():\n",
        "    \"\"\"测试阿里云百炼服务连接和模型是否可用\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"测试阿里云百炼服务连接: {DASHSCOPE_BASE_URL}\")\n",
        "\n",
        "        response = dashscope_client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[{\"role\": \"user\", \"content\": \"测试连接\"}],\n",
        "            max_tokens=5,\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.content:\n",
        "            logger.info(\"阿里云百炼服务连接成功，模型响应正常\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.error(\"模型验证失败: 无有效响应内容\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"阿里云百炼连接失败: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def find_md_files(input_folder):\n",
        "    \"\"\"递归遍历文件夹，查找所有 .md 文件\"\"\"\n",
        "    md_files = []\n",
        "    for root, dirs, files in os.walk(input_folder, topdown=True):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.md'):\n",
        "                md_files.append(os.path.join(root, file))\n",
        "    return md_files\n",
        "\n",
        "\n",
        "def check_dashscope_health():\n",
        "    \"\"\"检查阿里云百炼服务状态\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"检查阿里云百炼服务状态: {DASHSCOPE_BASE_URL}\")\n",
        "\n",
        "        response = dashscope_client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[{\"role\": \"user\", \"content\": \"健康检查\"}],\n",
        "            max_tokens=5,\n",
        "            timeout=15\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.content:\n",
        "            logger.info(\"阿里云百炼服务健康检查通过\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.warning(\"服务响应异常，但模型可能可用\")\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"阿里云百炼健康检查失败: {str(e)}\")\n",
        "        logger.warning(\"忽略错误，继续执行...\")\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def contains_keywords(text):\n",
        "    \"\"\"快速关键词匹配，判断文本是否含有核心或相关关键词\"\"\"\n",
        "    try:\n",
        "        return bool(KEYWORD_PATTERN.search(text))\n",
        "    except Exception as e:\n",
        "        logger.error(f\"关键词匹配失败: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def check_filename_relevance(filename):\n",
        "    \"\"\"根据文件名判断相关性，直接判断核心或相关领域\"\"\"\n",
        "    base_name = os.path.basename(filename).lower()\n",
        "    if CORE_KEYWORD_PATTERN.search(base_name):\n",
        "        return \"core\"  # 核心关键词\n",
        "    if RELATED_KEYWORD_PATTERN.search(base_name):\n",
        "        return \"related\"  # 相关领域\n",
        "    return \"unrelated\"  # 无关\n",
        "\n",
        "\n",
        "def classify_text(content, prompt_template, max_chars, retry_count=0):\n",
        "    \"\"\"使用阿里云百炼API分类文本，返回True为相关，False为不相关\"\"\"\n",
        "    if retry_count > RETRY_LIMIT:\n",
        "        logger.warning(f\"达到最大重试次数，默认通过\")\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        prompt = prompt_template.format(\n",
        "            core_keywords=\", \".join(CORE_KEYWORDS),\n",
        "            related_fields=\", \".join(RELATED_FIELDS),\n",
        "            max_chars=max_chars,\n",
        "            content=content[:max_chars]\n",
        "        )\n",
        "\n",
        "        time.sleep(random.uniform(0, REQUEST_INTERVAL))  # 避免频繁请求\n",
        "\n",
        "        response = dashscope_client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.1,\n",
        "            top_p=0.9,\n",
        "            max_tokens=50,\n",
        "            timeout=TIMEOUT\n",
        "        )\n",
        "\n",
        "        res_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        if any(x in res_text for x in [\"是\", \"相关\", \"yes\", \"保留\"]):\n",
        "            return True\n",
        "        elif any(x in res_text for x in [\"否\", \"无关\", \"no\", \"删除\"]):\n",
        "            return False\n",
        "        else:\n",
        "            logger.warning(f\"异常响应: {res_text[:50]}，默认保留\")\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"分类失败: {str(e)}，重试次数: {retry_count}\")\n",
        "        return classify_text(content, prompt_template, max_chars, retry_count + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def process_first_pass(file_path):\n",
        "    \"\"\"首次处理文件，判断是否直接通过或进入二次检测或丢弃\"\"\"\n",
        "    try:\n",
        "        relative_path = os.path.relpath(file_path, INPUT_FOLDER)\n",
        "        good_path = os.path.join(GOOD_FOLDER, relative_path)\n",
        "        bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
        "\n",
        "        # 已处理文件跳过\n",
        "        if os.path.exists(good_path) or os.path.exists(bad_path):\n",
        "            return (\"skip\", None)\n",
        "\n",
        "        # 空文件直接移至bad\n",
        "        if os.path.getsize(file_path) == 0:\n",
        "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
        "            shutil.move(file_path, bad_path)\n",
        "            return (\"empty\", None)\n",
        "\n",
        "        # 文件名相关性判断\n",
        "        filename_relevance = check_filename_relevance(file_path)\n",
        "        if filename_relevance == \"core\":\n",
        "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
        "            shutil.move(file_path, good_path)\n",
        "            return (\"moved\", None)\n",
        "        elif filename_relevance == \"related\":\n",
        "            # 读取部分内容分类\n",
        "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                content = f.read(MAX_CHARS_FIRST)\n",
        "            if not content.strip():\n",
        "                os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
        "                shutil.move(file_path, bad_path)\n",
        "                return (\"empty\", None)\n",
        "\n",
        "            is_related = classify_text(content, FIRST_PROMPT_TEMPLATE, MAX_CHARS_FIRST)\n",
        "            if is_related:\n",
        "                os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
        "                shutil.move(file_path, good_path)\n",
        "                return (\"moved\", None)\n",
        "            else:\n",
        "                tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
        "                os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
        "                shutil.move(file_path, tmp_path)\n",
        "                return (\"tmp\", tmp_path)\n",
        "        else:\n",
        "            # 文件名无关，移至tmp待二次检测\n",
        "            tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
        "            os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
        "            shutil.move(file_path, tmp_path)\n",
        "            return (\"tmp\", tmp_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"首次处理失败 {file_path}: {str(e)}\")\n",
        "        relative_path = os.path.relpath(file_path, INPUT_FOLDER)\n",
        "        tmp_path = os.path.join(TMP_FOLDER, relative_path)\n",
        "        os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
        "        shutil.move(file_path, tmp_path)\n",
        "        return (\"tmp\", tmp_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def process_second_pass(file_path):\n",
        "    \"\"\"二次处理：对tmp目录中文件进行二次分类，移动至good或bad\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            content = f.read(MAX_CHARS_SECOND)\n",
        "\n",
        "        if not content.strip():\n",
        "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
        "            bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
        "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
        "            shutil.move(file_path, bad_path)\n",
        "            return False\n",
        "\n",
        "        is_related = classify_text(content, SECOND_PROMPT_TEMPLATE, MAX_CHARS_SECOND)\n",
        "        if is_related:\n",
        "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
        "            good_path = os.path.join(GOOD_FOLDER, relative_path)\n",
        "            os.makedirs(os.path.dirname(good_path), exist_ok=True)\n",
        "            shutil.move(file_path, good_path)\n",
        "            return True\n",
        "        else:\n",
        "            relative_path = os.path.relpath(file_path, TMP_FOLDER)\n",
        "            bad_path = os.path.join(BAD_FOLDER, relative_path)\n",
        "            os.makedirs(os.path.dirname(bad_path), exist_ok=True)\n",
        "            shutil.move(file_path, bad_path)\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"二次处理失败 {file_path}: {str(e)}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def cleanup_empty_directories(root_folder):\n",
        "    \"\"\"清理指定目录下的所有空目录\"\"\"\n",
        "    if not PARALLEL_PROCESSING:\n",
        "        for root, dirs, _ in os.walk(root_folder, topdown=False):\n",
        "            for dir_name in dirs:\n",
        "                dir_path = os.path.join(root, dir_name)\n",
        "                try:\n",
        "                    if not os.listdir(dir_path):\n",
        "                        os.rmdir(dir_path)\n",
        "                        logger.debug(f\"清理空目录: {dir_path}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"无法清理目录 {dir_path}: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # 并行清理\n",
        "    dirs_to_check = []\n",
        "    for root, dirs, _ in os.walk(root_folder, topdown=False):\n",
        "        for dir_name in dirs:\n",
        "            dirs_to_check.append(os.path.join(root, dir_name))\n",
        "\n",
        "    def remove_if_empty(dir_path):\n",
        "        try:\n",
        "            if not os.listdir(dir_path):\n",
        "                os.rmdir(dir_path)\n",
        "                logger.debug(f\"清理空目录: {dir_path}\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"无法清理目录 {dir_path}: {str(e)}\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        list(tqdm(executor.map(remove_if_empty, dirs_to_check),\n",
        "                  total=len(dirs_to_check), desc=\"清理空目录\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def main():\n",
        "    logger.info(\"===== 海上风电文档分类器（阿里云百炼版）启动 =====\")\n",
        "    logger.info(f\"输入目录: {INPUT_FOLDER}\")\n",
        "    logger.info(f\"使用模型: {MODEL_NAME} | 批次大小: {BATCH_SIZE}\")\n",
        "    logger.info(f\"API地址: {DASHSCOPE_BASE_URL}\")\n",
        "\n",
        "    if not test_dashscope_connection() or not check_dashscope_health():\n",
        "        logger.error(\"服务检查失败，但继续执行...\")\n",
        "\n",
        "    logger.info(\"===== 开始第一阶段：处理原始文件夹中的文件 =====\")\n",
        "    first_pass_files = find_md_files(INPUT_FOLDER)\n",
        "    total_files = len(first_pass_files)\n",
        "    if total_files == 0:\n",
        "        logger.info(\"原始文件夹中未找到MD文件，直接进入第二阶段\")\n",
        "    else:\n",
        "        logger.info(f\"共找到 {total_files} 个MD文件，开始分批次处理...\")\n",
        "\n",
        "        first_stats = {\"moved\": 0, \"tmp\": 0, \"empty\": 0, \"error\": 0, \"skip\": 0}\n",
        "        total_batch = (total_files + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "        for batch_idx in range(total_batch):\n",
        "            start = batch_idx * BATCH_SIZE\n",
        "            end = min((batch_idx + 1) * BATCH_SIZE, total_files)\n",
        "            batch_files = first_pass_files[start:end]\n",
        "            batch_num = batch_idx + 1\n",
        "            logger.info(f\"\\n===== 批次 {batch_num}/{total_batch} 开始（{len(batch_files)}个文件） =====\")\n",
        "\n",
        "            batch_stats = {\"moved\": 0, \"tmp\": 0, \"empty\": 0, \"error\": 0, \"skip\": 0}\n",
        "\n",
        "            if not PARALLEL_PROCESSING:\n",
        "                for file in tqdm(batch_files, desc=f\"批次{batch_num}处理\"):\n",
        "                    try:\n",
        "                        result, _ = process_first_pass(file)\n",
        "                        batch_stats[result] += 1\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"处理异常: {str(e)}\")\n",
        "                        batch_stats[\"error\"] += 1\n",
        "            else:\n",
        "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "                    futures = {executor.submit(process_first_pass, f): f for f in batch_files}\n",
        "                    with tqdm(total=len(batch_files), desc=f\"批次{batch_num}处理\") as pbar:\n",
        "                        for future in as_completed(futures):\n",
        "                            try:\n",
        "                                result, _ = future.result()\n",
        "                                batch_stats[result] += 1\n",
        "                                pbar.update(1)\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"批次{batch_num}任务异常: {str(e)}\")\n",
        "                                batch_stats[\"error\"] += 1\n",
        "                                pbar.update(1)\n",
        "\n",
        "            first_stats[\"moved\"] += batch_stats[\"moved\"]\n",
        "            first_stats[\"tmp\"] += batch_stats[\"tmp\"]\n",
        "            first_stats[\"empty\"] += batch_stats[\"empty\"]\n",
        "            first_stats[\"error\"] += batch_stats[\"error\"]\n",
        "            first_stats[\"skip\"] += batch_stats[\"skip\"]\n",
        "\n",
        "            logger.info(f\"批次{batch_num}处理结果: 通过={batch_stats['moved']}, 待二次检测={batch_stats['tmp']}, 空文件={batch_stats['empty']}, 错误={batch_stats['error']}\")\n",
        "\n",
        "        logger.info(\"\\n\" + \"=\" * 60)\n",
        "        logger.info(\"第一阶段处理完成！\")\n",
        "        logger.info(\"第一阶段统计:\")\n",
        "        logger.info(f\"  直接通过文件: {first_stats['moved']}（已移动到good文件夹）\")\n",
        "        logger.info(f\"  待二次检测文件: {first_stats['tmp']}（已移动到tmp文件夹）\")\n",
        "        logger.info(f\"  空文件: {first_stats['empty']}（已移动到bad文件夹）\")\n",
        "        logger.info(f\"  错误文件: {first_stats['error']}（已移动到bad文件夹）\")\n",
        "        logger.info(f\"  跳过文件: {first_stats['skip']}\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "        cleanup_empty_directories(INPUT_FOLDER)\n",
        "        logger.info(f\"原始文件夹空目录清理完成，当前状态: {'空' if not os.listdir(INPUT_FOLDER) else '非空'}\")\n",
        "\n",
        "    logger.info(\"\\n===== 开始第二阶段：处理tmp文件夹中的文件 =====\")\n",
        "    second_pass_files = find_md_files(TMP_FOLDER)\n",
        "    total_second_files = len(second_pass_files)\n",
        "    if total_second_files == 0:\n",
        "        logger.info(\"tmp文件夹中未找到MD文件，处理完成\")\n",
        "    else:\n",
        "        logger.info(f\"tmp文件夹中共找到 {total_second_files} 个MD文件，开始二次检测...\")\n",
        "\n",
        "        second_stats = {\"moved\": 0, \"rejected\": 0, \"error\": 0}\n",
        "        total_second_batch = (total_second_files + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "        for batch_idx in range(total_second_batch):\n",
        "            start = batch_idx * BATCH_SIZE\n",
        "            end = min((batch_idx + 1) * BATCH_SIZE, total_second_files)\n",
        "            batch_files = second_pass_files[start:end]\n",
        "            batch_num = batch_idx + 1\n",
        "            logger.info(f\"\\n===== 二次检测批次 {batch_num}/{total_second_batch} 开始 =====\")\n",
        "\n",
        "            batch_stats = {\"moved\": 0, \"rejected\": 0, \"error\": 0}\n",
        "\n",
        "            if not PARALLEL_PROCESSING:\n",
        "                for file in tqdm(batch_files, desc=f\"批次{batch_num}二次检测\"):\n",
        "                    try:\n",
        "                        if process_second_pass(file):\n",
        "                            batch_stats[\"moved\"] += 1\n",
        "                        else:\n",
        "                            batch_stats[\"rejected\"] += 1\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"处理异常: {str(e)}\")\n",
        "                        batch_stats[\"error\"] += 1\n",
        "            else:\n",
        "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "                    futures = {executor.submit(process_second_pass, f): f for f in batch_files}\n",
        "                    with tqdm(total=len(batch_files), desc=f\"批次{batch_num}二次检测\") as pbar:\n",
        "                        for future in as_completed(futures):\n",
        "                            try:\n",
        "                                if future.result():\n",
        "                                    batch_stats[\"moved\"] += 1\n",
        "                                else:\n",
        "                                    batch_stats[\"rejected\"] += 1\n",
        "                                pbar.update(1)\n",
        "                            except Exception as e:\n",
        "                                logger.error(f\"批次{batch_num}任务异常: {str(e)}\")\n",
        "                                batch_stats[\"error\"] += 1\n",
        "                                pbar.update(1)\n",
        "\n",
        "            second_stats[\"moved\"] += batch_stats[\"moved\"]\n",
        "            second_stats[\"rejected\"] += batch_stats[\"rejected\"]\n",
        "            second_stats[\"error\"] += batch_stats[\"error\"]\n",
        "\n",
        "            logger.info(f\"二次检测批次{batch_num}结果: 通过={batch_stats['moved']}（已移动到good文件夹）, 拒绝={batch_stats['rejected']}（已移动到bad文件夹）, 错误={batch_stats['error']}\")\n",
        "\n",
        "        logger.info(\"\\n\" + \"=\" * 60)\n",
        "        logger.info(\"第二阶段处理完成！\")\n",
        "        logger.info(\"第二阶段统计:\")\n",
        "        logger.info(f\"  二次检测通过文件: {second_stats['moved']}（已移动到good文件夹）\")\n",
        "        logger.info(f\"  最终拒绝文件: {second_stats['rejected']}（已移动到bad文件夹）\")\n",
        "        logger.info(f\"  错误文件: {second_stats['error']}（保留在tmp文件夹）\")\n",
        "        logger.info(\"=\" * 60)\n",
        "\n",
        "        cleanup_empty_directories(TMP_FOLDER)\n",
        "        logger.info(f\"tmp文件夹空目录清理完成，当前状态: {'空' if not os.listdir(TMP_FOLDER) else '非空'}\")\n",
        "\n",
        "    logger.info(\"\\n\" + \"=\" * 60)\n",
        "    logger.info(\"所有文件处理完成！\")\n",
        "    logger.info(\"最终统计:\")\n",
        "    logger.info(f\"  通过文件总数: {first_stats.get('moved', 0) + second_stats.get('moved', 0)}\")\n",
        "    logger.info(f\"  拒绝文件: {first_stats.get('empty', 0) + second_stats.get('rejected', 0)}\")\n",
        "    logger.info(f\"  临时保留文件: {first_stats.get('tmp', 0) + second_stats.get('error', 0)}\")\n",
        "    logger.info(f\"  原始文件夹状态: {'空' if not os.listdir(INPUT_FOLDER) else '非空'}\")\n",
        "    logger.info(f\"  通过文件存放于: {GOOD_FOLDER}\")\n",
        "    logger.info(f\"  拒绝文件存放于: {BAD_FOLDER}\")\n",
        "    logger.info(f\"  临时保留文件存放于: {TMP_FOLDER}\")\n",
        "    logger.info(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.warning(\"程序被用户中断\")\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"程序异常终止: {str(e)}\")\n",
        "        sys.exit(1)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
